# Building Blocks Common ID Tool

# Generic development tasks

## Setting up for development

#### Step 1: Clone & init this repo and the algorithm repositories

```
git clone ....
git submodule init
git submodule update
npm install
```


#### Step 2: Build the UI

```
# In the src/renderer directory
npm install
npm run build
```

this'll output the compiled UI files into the `dist` directory.


#### Step 4: Start the application

```
DEBUG=CID:* npm start
```


# Running the unit tests

Unit tests for the algorithm (shared and algorithm-specific) are written using the JEST test framework. Run the test suite:

(the `--experimental-vm-modules` node option is required to load the ES module code for the frontend tests)


```bash
# the `--experimental-vm-modules` node option is required to load the ES module code
# for the frontend tests
export NODE_OPTIONS="$NODE_OPTIONS --experimental-vm-modules"

# Now both backend and frontend tests can be ran
npx jest
```

Or get the test coverage using

```bash
npx jest --coverage
```


# Development logging

The application uses the `debug` package to do logging. To log every CommonID-related message to set the environment variable `DEBUG` to `CID:*`.

For example to run the application for development with every CommonID component logging to the console:

```
DEBUG=CID:* npm start
```


All logging lines are prefixed with `CID:` (for CommonID), and should look like the following:

```
  CID:loadConfig CONFIG HASH: 3b4b6ab8a68202ebcf3221d5c1a728b7 +33ms
  CID:loadSaltFile Attempting to load salt file from  /Users/.../Library/Preferences/BuildingBlocks/WFP SYR NWS stage (BE85CAE8) â€“ Public.asc +0ms
  CID:loadSaltFile SALT FILE looks OK +1ms
  CID:ConfigStore Backup config validation success - using it as config +34ms
```

To see only specific log lines refine the `CID:*` pattern.

## Activating an algorithm for use

To set which algorithm is used by the app the command-line tool `tools/activate-algo.js` can be used:

```
$ node tools/activate-algo.js algo-gos

Activating algoirhtm: algo-gos
Generating ****/src/main/active_algorithm.js
Copying backup config from ****/src/main/algo-gos/config/config.backup.toml
                        to ****/src/main/config.backup.toml


$ node tools/activate-algo.js algo-uscadi

Activating algoirhtm: algo-uscadi
Generating ****/src/main/active_algorithm.js
Copying backup config from ****/src/main/algo-uscadi/config/config.backup.toml
                        to ****/src/main/config.backup.toml
```


This generates a new `src/main/active_algorithm.js` which is a re-export of the selected algorithm's `index.js` and copies the backup configuration to `src/main/config.backup.toml`.

Manually doing these steps also activates the algorithm.

## Generating a config signature hash

To generate the config signature for the config file the tool `tools/config-signature.js` can be used:

```
$ node tools/config-signature.js src/main/algo-uscadi/config/config.backup.toml

Opening file:  src/main/algo-uscadi/config/config.backup.toml
HASH: 9000d0f670be5287bc86bc1b74b48d34
```

This returns the signature hash that can be embedded in the config file. The signature can be copy-pasted into the `signature.config_signature` value in the config file (the signature is generated by ignoring the `signature` key)



nd Line Tools installed. To check whether it is available, try `xcode-select --install` and follow the instructions.

# Processing pipeline overview

The processing uses the following steps:

## Configuration

- The `src/main/algo-shared/config/ConfigStore` ConfigStore attempts to load the configuration from the appllication directory or the backup location (app bundle) if the primary configuration fails to load. It also handles updating the user configuration file on config changes.

- The terms and conditions are also handled by the ConfigStore using the `src/main/algo-shared/config/appConfig` application config save/write process

## Pre-processing (validation)

- The `src/main/algo-shared/decoding` Decoders (CSV and XLSX) read the source file and convert it (using the `config.source` setup) to a Document with Sheets containing the input data with column aliases renamed

- The `src/processing` pre-processing function identifies if the target is a mapping document based on the current configuration and the data in the file and sets up validation accordingly

- The `src/main/algo-shared/validation` Validators are setup based on the active configuration, and ran against the Document.

- If there are errors, the `src/main/algo-shared/encoding` Encoders (CSV and XLSX) write the validation error output based on `[destination_errors]` section of the active configuration

- The frontend shows the results and either allows processing or shows the errors

## Processing

- The `src/main/algo-shared/decoding` Decoders (CSV and XLSX) read the source file and convert it (using the `config.source` setup) to a Document with Sheets containing the input data with column aliases renamed

- The `src/processing` processing function identifies if the target is a mapping document based on the current configuration and the data in the file. Using the active configuration it collects data into `static` `to_translate` and `reference` buckets per-row and passes it to the active algorithm for processing

- The active algorithm takes the `{ static:[...], to_translate:[...], reference: [...] }` per-row data and returns a map with the columns it wants to add -- ex: `{ USCADI: "....", DOCUMENT_HASH: "..." }`

- The data returned by the algorithm is merged into the source rows so the encoders can package multiple different outputs

- The `src/main/algo-shared/encoding` Encoders (CSV and XLSX) write the output based on the relevant `[destination]` / `[destination_map]` section of the active configuration.

